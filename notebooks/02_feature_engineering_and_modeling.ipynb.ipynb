{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0067fee-524f-4840-b175-5ae0bc6c51d8",
   "metadata": {},
   "source": [
    "# **Fintech SaaS Churn Intelligence**\n",
    "## **Notebook 02 - Feature Engineering**\n",
    "\n",
    "This notebook begins the predictive modeling workflow using the processed datasets from Notebook 01.  \n",
    "Our focus here is to build high-signal behavioral features and prepare a clean modeling dataset.\n",
    "\n",
    "### **Objectives**\n",
    "1. Load curated user-level and synthetic event-level datasets  \n",
    "2. Engineer behavioral, recency, and engagement features  \n",
    "3. Build a unified modeling dataset for churn prediction  \n",
    "4. Perform sanity checks before modeling  \n",
    "\n",
    "By the end of this section, we will have a robust feature table ready for model training.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac62f1b0-1d54-4f63-a9d0-65773c3dbd84",
   "metadata": {},
   "source": [
    "## IMPORT LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "23872b0e-0dbe-44b7-9560-0b78b3dc9f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports ready. Pandas version: 2.3.3\n"
     ]
    }
   ],
   "source": [
    "# Standard imports and environment setup\n",
    "import os\n",
    "import pandas as pd            # dataframes\n",
    "import numpy as np             # numerical ops\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "\n",
    "# For fast SQL-like queries if needed later\n",
    "import duckdb\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# feature Engineering\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, precision_recall_curve\n",
    "\n",
    "\n",
    "# Basic utilities\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Notebook display niceties\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.width', 140)\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "print(\"Imports ready. Pandas version:\", pd.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5685eee1-19d3-480e-af03-f25f21eed69d",
   "metadata": {},
   "source": [
    "## 1. Create synthetic event aggregates \n",
    "We ensure all IDs share a consistent `string` dtype.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "726dbf59-cf4d-438d-883f-28b8b07b9d3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using balanced remapped events: ../data/synthetic/events_telco_mapped_balanced.csv\n",
      "agg_telco written to ../data/processed/agg_telco.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>events_count</th>\n",
       "      <th>unique_active_days</th>\n",
       "      <th>first_event_ts</th>\n",
       "      <th>last_event_ts</th>\n",
       "      <th>support_contacts_count</th>\n",
       "      <th>error_event_count</th>\n",
       "      <th>events_last_30d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0002-ORFBO</td>\n",
       "      <td>56</td>\n",
       "      <td>51</td>\n",
       "      <td>2023-02-10 05:39:48</td>\n",
       "      <td>2024-10-28 09:34:14</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0003-MKNFE</td>\n",
       "      <td>65</td>\n",
       "      <td>63</td>\n",
       "      <td>2023-02-10 19:34:47</td>\n",
       "      <td>2025-01-13 18:46:13</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0004-TLHLJ</td>\n",
       "      <td>27</td>\n",
       "      <td>26</td>\n",
       "      <td>2023-02-17 17:23:27</td>\n",
       "      <td>2024-12-09 19:02:28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0011-IGKFF</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>2023-03-13 15:42:47</td>\n",
       "      <td>2024-08-04 02:21:28</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0013-EXCHZ</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>2023-01-06 20:47:02</td>\n",
       "      <td>2024-05-07 02:04:11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id  events_count  unique_active_days      first_event_ts       last_event_ts  support_contacts_count  error_event_count  \\\n",
       "0  0002-ORFBO            56                  51 2023-02-10 05:39:48 2024-10-28 09:34:14                       2                  3   \n",
       "1  0003-MKNFE            65                  63 2023-02-10 19:34:47 2025-01-13 18:46:13                       0                  5   \n",
       "2  0004-TLHLJ            27                  26 2023-02-17 17:23:27 2024-12-09 19:02:28                       1                  1   \n",
       "3  0011-IGKFF            31                  29 2023-03-13 15:42:47 2024-08-04 02:21:28                       1                  2   \n",
       "4  0013-EXCHZ            38                  38 2023-01-06 20:47:02 2024-05-07 02:04:11                       0                  0   \n",
       "\n",
       "   events_last_30d  \n",
       "0               16  \n",
       "1               21  \n",
       "2                7  \n",
       "3                7  \n",
       "4               10  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Rebuild agg_telco from remapped events or from original events (with remapping fallback)\n",
    "\n",
    "processed_dir = \"../data/processed\"\n",
    "synthetic_dir = \"../data/synthetic\"\n",
    "os.makedirs(processed_dir, exist_ok=True)\n",
    "\n",
    "# candidate remapped file (balanced preferred)\n",
    "balanced_path = os.path.join(synthetic_dir, \"events_telco_mapped_balanced.csv\")\n",
    "remapped_path = os.path.join(synthetic_dir, \"events_telco_mapped.csv\")\n",
    "original_events_path = os.path.join(synthetic_dir, \"events.csv\")\n",
    "\n",
    "# decide which events file to use\n",
    "if os.path.exists(balanced_path):\n",
    "    events_src = balanced_path\n",
    "    print(\"Using balanced remapped events:\", balanced_path)\n",
    "elif os.path.exists(remapped_path):\n",
    "    events_src = remapped_path\n",
    "    print(\"Using remapped events:\", remapped_path)\n",
    "elif os.path.exists(original_events_path):\n",
    "    events_src = original_events_path\n",
    "    print(\"Using original synthetic events file (events.csv); will remap to telco IDs below:\", original_events_path)\n",
    "else:\n",
    "    raise FileNotFoundError(\"No events file found. Place a synthetic events CSV under data/synthetic/ named events.csv or events_telco_mapped_balanced.csv\")\n",
    "\n",
    "# load events (do not assume signup_date exists)\n",
    "events = pd.read_csv(events_src, low_memory=False, parse_dates=['timestamp'], infer_datetime_format=True)\n",
    "events['user_id'] = events['user_id'].astype(str)\n",
    "\n",
    "# If using original events.csv (no remapping), attempt to remap now using users list.\n",
    "if events_src.endswith(\"events.csv\"):\n",
    "    # load users to remap (if available)\n",
    "    users_path = os.path.join(processed_dir, \"users_normalized.csv\")\n",
    "    if not os.path.exists(users_path):\n",
    "        # try raw users\n",
    "        raw_users_path = \"../data/raw/telco_churn.csv\"\n",
    "        if os.path.exists(raw_users_path):\n",
    "            users = pd.read_csv(raw_users_path, low_memory=False)\n",
    "            # ensure a user_id column exists; try common names\n",
    "            if 'user_id' not in users.columns:\n",
    "                if 'customerID' in users.columns:\n",
    "                    users['user_id'] = users['customerID'].astype(str)\n",
    "                else:\n",
    "                    # create synthetic user ids from index (last-resort)\n",
    "                    users['user_id'] = users.index.astype(str)\n",
    "            # save normalized users file for reproducibility\n",
    "            users[['user_id']].to_csv(users_path, index=False)\n",
    "            print(\"Created minimal users_normalized.csv from raw telco file.\")\n",
    "        else:\n",
    "            raise FileNotFoundError(\"Cannot remap events because users table not found. Place users_normalized.csv under data/processed/ or telco raw under data/raw/.\")\n",
    "\n",
    "    # load canonical users and remap events balancedly (guarantee >=1 per user)\n",
    "    users = pd.read_csv(users_path, low_memory=False)\n",
    "    telco_ids = users['user_id'].astype(str).unique().tolist()\n",
    "    n_telco = len(telco_ids)\n",
    "    n_events = len(events)\n",
    "    print(f\"Remapping {n_events} events to {n_telco} telco users (guarantee >=1 per user).\")\n",
    "\n",
    "    # simple balanced remap: sample one event per user then distribute remainder with weights\n",
    "    rng = np.random.default_rng(42)\n",
    "\n",
    "    if n_events < n_telco:\n",
    "        raise ValueError(\"Not enough events to guarantee one-per-user. Generate more synthetic events first.\")\n",
    "\n",
    "    # 1) pick sample indices for guaranteed assignment\n",
    "    guaranteed_idx = events.sample(n=n_telco, random_state=42).index\n",
    "    events_remap = events.copy()\n",
    "    events_remap.loc[guaranteed_idx, 'user_id'] = telco_ids  # assign 1-to-1 deterministically via order\n",
    "\n",
    "    # 2) remaining events: weighted assignment (power-law like)\n",
    "    remaining_mask = ~events.index.isin(guaranteed_idx)\n",
    "    remaining_indices = events.index[remaining_mask]\n",
    "    top = int(0.10 * n_telco)\n",
    "    mid = int(0.40 * n_telco)\n",
    "    rest = n_telco - (top + mid)\n",
    "    weights = np.concatenate([np.full(top, 5.0), np.full(mid, 2.0), np.full(rest, 1.0)])\n",
    "    weights = weights / weights.sum()\n",
    "    # sample telco ids for remaining events\n",
    "    sampled = rng.choice(telco_ids, size=len(remaining_indices), replace=True, p=weights)\n",
    "    events_remap.loc[remaining_indices, 'user_id'] = sampled\n",
    "\n",
    "    events = events_remap\n",
    "    # persist remapped events for reproducibility\n",
    "    out_remapped = os.path.join(synthetic_dir, \"events_telco_mapped_balanced.csv\")\n",
    "    events.to_csv(out_remapped, index=False)\n",
    "    print(\"Saved remapped events to:\", out_remapped)\n",
    "\n",
    "# At this point 'events' is the remapped event log (user_id = telco ids). Build aggregates:\n",
    "events['timestamp'] = pd.to_datetime(events['timestamp'], errors='coerce')\n",
    "events['active_day'] = events['timestamp'].dt.date\n",
    "\n",
    "# Compute aggregates\n",
    "events_count = events.groupby('user_id').size().rename('events_count').reset_index()\n",
    "unique_active_days = events.groupby('user_id')['active_day'].nunique().rename('unique_active_days').reset_index()\n",
    "first_event = events.groupby('user_id')['timestamp'].min().rename('first_event_ts').reset_index()\n",
    "last_event  = events.groupby('user_id')['timestamp'].max().rename('last_event_ts').reset_index()\n",
    "support_cnt = events.loc[events['event_type']=='support_contact'].groupby('user_id').size().rename('support_contacts_count').reset_index()\n",
    "error_cnt   = events.loc[events['event_type']=='error_event'].groupby('user_id').size().rename('error_event_count').reset_index()\n",
    "\n",
    "reference_date = pd.to_datetime(\"2023-12-31\")\n",
    "events_last30 = events[events['timestamp'] >= (reference_date - pd.Timedelta(days=30))]\n",
    "events_30d = events_last30.groupby('user_id').size().rename('events_last_30d').reset_index()\n",
    "\n",
    "# Merge into tidy agg_telco\n",
    "agg_telco = events_count.merge(unique_active_days, on='user_id', how='left') \\\n",
    "                        .merge(first_event, on='user_id', how='left') \\\n",
    "                        .merge(last_event, on='user_id', how='left') \\\n",
    "                        .merge(support_cnt, on='user_id', how='left') \\\n",
    "                        .merge(error_cnt, on='user_id', how='left') \\\n",
    "                        .merge(events_30d, on='user_id', how='left')\n",
    "\n",
    "# fill NaNs for counts with 0 (no activity)\n",
    "for c in ['events_count','unique_active_days','support_contacts_count','error_event_count','events_last_30d']:\n",
    "    if c in agg_telco.columns:\n",
    "        agg_telco[c] = agg_telco[c].fillna(0).astype(int)\n",
    "\n",
    "# Save agg_telco\n",
    "agg_path = os.path.join(processed_dir, \"agg_telco.csv\")\n",
    "agg_telco.to_csv(agg_path, index=False)\n",
    "print(\"agg_telco written to\", agg_path)\n",
    "display(agg_telco.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382eb5ef-09b9-4319-837f-bb7eea0ffca6",
   "metadata": {},
   "source": [
    "## 2. Load User-Level and Event-Level Data  \n",
    "We begin by loading:\n",
    "\n",
    "- `users` → Telco customer dataset with normalized churn fields (from Notebook 01)  \n",
    "- `agg_telco` → Synthetic event aggregates computed in Notebook 01  \n",
    "- `events` → Raw synthetic events (optional, useful for inspection)\n",
    "\n",
    "We ensure all IDs share a consistent `string` dtype.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c20da78b-2188-4b61-9633-4a376799a1f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded users: (7043, 28)\n",
      "Loaded agg_telco: (7043, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>events_count</th>\n",
       "      <th>unique_active_days</th>\n",
       "      <th>first_event_ts</th>\n",
       "      <th>last_event_ts</th>\n",
       "      <th>support_contacts_count</th>\n",
       "      <th>error_event_count</th>\n",
       "      <th>events_last_30d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0002-ORFBO</td>\n",
       "      <td>56</td>\n",
       "      <td>51</td>\n",
       "      <td>2023-02-10 05:39:48</td>\n",
       "      <td>2024-10-28 09:34:14</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0003-MKNFE</td>\n",
       "      <td>65</td>\n",
       "      <td>63</td>\n",
       "      <td>2023-02-10 19:34:47</td>\n",
       "      <td>2025-01-13 18:46:13</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0004-TLHLJ</td>\n",
       "      <td>27</td>\n",
       "      <td>26</td>\n",
       "      <td>2023-02-17 17:23:27</td>\n",
       "      <td>2024-12-09 19:02:28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0011-IGKFF</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>2023-03-13 15:42:47</td>\n",
       "      <td>2024-08-04 02:21:28</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0013-EXCHZ</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>2023-01-06 20:47:02</td>\n",
       "      <td>2024-05-07 02:04:11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id  events_count  unique_active_days       first_event_ts        last_event_ts  support_contacts_count  error_event_count  \\\n",
       "0  0002-ORFBO            56                  51  2023-02-10 05:39:48  2024-10-28 09:34:14                       2                  3   \n",
       "1  0003-MKNFE            65                  63  2023-02-10 19:34:47  2025-01-13 18:46:13                       0                  5   \n",
       "2  0004-TLHLJ            27                  26  2023-02-17 17:23:27  2024-12-09 19:02:28                       1                  1   \n",
       "3  0011-IGKFF            31                  29  2023-03-13 15:42:47  2024-08-04 02:21:28                       1                  2   \n",
       "4  0013-EXCHZ            38                  38  2023-01-06 20:47:02  2024-05-07 02:04:11                       0                  0   \n",
       "\n",
       "   events_last_30d  \n",
       "0               16  \n",
       "1               21  \n",
       "2                7  \n",
       "3                7  \n",
       "4               10  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step: Load users_normalized and agg_telco with safety checks\n",
    "import pandas as pd, os\n",
    "\n",
    "users_path = \"../data/processed/users_normalized.csv\"\n",
    "agg_path = \"../data/processed/agg_telco.csv\"\n",
    "\n",
    "if not os.path.exists(users_path):\n",
    "    # try alternative names: users_features_telco_mapped.csv or users_features.csv\n",
    "    alt = \"../data/processed/users_features_telco_mapped.csv\"\n",
    "    if os.path.exists(alt):\n",
    "        users_path = alt\n",
    "        print(\"Using alternative users file:\", alt)\n",
    "    else:\n",
    "        raise FileNotFoundError(\"users_normalized.csv not found under data/processed/. Please run Notebook 01 or provide users table.\")\n",
    "\n",
    "users = pd.read_csv(users_path, parse_dates=['start_date','churn_date'], low_memory=False)\n",
    "agg_telco = pd.read_csv(agg_path, low_memory=False)\n",
    "\n",
    "# normalize id types\n",
    "users['user_id'] = users['user_id'].astype(str)\n",
    "agg_telco['user_id'] = agg_telco['user_id'].astype(str)\n",
    "\n",
    "print(\"Loaded users:\", users.shape)\n",
    "print(\"Loaded agg_telco:\", agg_telco.shape)\n",
    "display(agg_telco.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2cca72-a5a3-4398-b12b-54db09c76e8c",
   "metadata": {},
   "source": [
    "## 3. Clean Duplicate Columns  \n",
    "During earlier processing, exploratory merges can introduce duplicate column names, which cause:\n",
    "\n",
    "- SHAP failures  \n",
    "- Pandas merge inconsistencies  \n",
    "- Feature collisions in ML models  \n",
    "\n",
    "We apply a strict deduplication rule to ensure every column name is unique.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f026f3f1-cdd0-4254-a07f-596df2a94f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users columns: 28\n",
      "Agg_telco columns: 8\n"
     ]
    }
   ],
   "source": [
    "def drop_duplicate_columns(df):\n",
    "    \"\"\"Ensure each column name appears once.\"\"\"\n",
    "    return df.loc[:, ~df.columns.duplicated()]\n",
    "\n",
    "users = drop_duplicate_columns(users)\n",
    "agg_telco = drop_duplicate_columns(agg_telco)\n",
    "\n",
    "print(\"Users columns:\", len(users.columns))\n",
    "print(\"Agg_telco columns:\", len(agg_telco.columns))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83703505-2ddb-4a7a-86a2-7bc9184a1c2b",
   "metadata": {},
   "source": [
    "## 4. Merge Synthetic Behavioral Features Into Telco Users  \n",
    "We perform a **single clean merge**:\n",
    "\n",
    "- Left table: Telco users  \n",
    "- Right table: aggregated synthetic behavior  \n",
    "- Suffix `_agg` added only where a name collision occurs  \n",
    "- All duplicate columns dropped after merge  \n",
    "\n",
    "This gives us a unified modeling dataset with both demographic and behavioral signals.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2e9e58df-ee2a-4ee2-9f42-c1df037d7462",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged dataset shape: (7043, 35)\n"
     ]
    }
   ],
   "source": [
    "users_merged = users.merge(\n",
    "    agg_telco,\n",
    "    on=\"user_id\",\n",
    "    how=\"left\",\n",
    "    suffixes=('', '_agg')\n",
    ")\n",
    "\n",
    "# Drop any remaining duplicates\n",
    "users_merged = drop_duplicate_columns(users_merged)\n",
    "\n",
    "print(\"Merged dataset shape:\", users_merged.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3c4195-f789-466e-b36b-7cc9c4ea1937",
   "metadata": {},
   "source": [
    "## 4. Consolidate / Overwrite Aggregated Feature Columns  \n",
    "If a feature appears both in Telco and in the synthetic aggregates, we:\n",
    "\n",
    "1. Prefer the event-derived (`_agg`) version  \n",
    "2. Overwrite the base version  \n",
    "3. Fill missing counts with zero  \n",
    "4. Leave timestamps as NaT until processed in the next step  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b7c7c416-a3d5-46ce-a873-25c4553d4969",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count features after standardization:\n",
      "events_count              int64\n",
      "unique_active_days        int64\n",
      "support_contacts_count    int64\n",
      "error_event_count         int64\n",
      "events_last_30d           int64\n",
      "dtype: object\n",
      "       events_count  unique_active_days  support_contacts_count  error_event_count  events_last_30d\n",
      "count   7043.000000         7043.000000             7043.000000        7043.000000      7043.000000\n",
      "mean      53.825075           49.964930                1.077240           2.133466        15.761607\n",
      "std       34.984385           29.571455                1.259555           1.990768        10.819822\n",
      "min       13.000000           13.000000                0.000000           0.000000         1.000000\n",
      "25%       30.000000           29.000000                0.000000           1.000000         9.000000\n",
      "50%       44.000000           42.000000                1.000000           2.000000        13.000000\n",
      "75%       62.000000           58.000000                2.000000           3.000000        19.000000\n",
      "max      185.000000          158.000000               11.000000          16.000000        66.000000\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# Standardization and type-correction of count-based behavioral features\n",
    "# ===================================================================\n",
    "\n",
    "# Define the list of count features that represent user activity, support usage, and errors\n",
    "# These features are critical behavioral signals for churn prediction and engagement analysis\n",
    "count_features = [\n",
    "    'events_count',          # Total number of events performed by the user\n",
    "    'unique_active_days',    # Number of distinct calendar days the user was active\n",
    "    'support_contacts_count',# Number of times the user contacted customer support\n",
    "    'error_event_count',     # Number of error or failure events recorded\n",
    "    'events_last_30d',       # Number of events in the most recent 30-day window\n",
    "]\n",
    "\n",
    "# Iterate over each count feature to ensure data quality and consistency\n",
    "for col in count_features:\n",
    "    \n",
    "    # Check for legacy/aggregated column names (e.g., from previous pipeline versions)\n",
    "    # Some features may have been computed under a different name (e.g., 'events_count_agg')\n",
    "    agg_col = col + \"_agg\"\n",
    "    if agg_col in users_merged.columns:\n",
    "        # Prefer the explicitly aggregated version if it exists\n",
    "        users_merged[col] = users_merged[agg_col]\n",
    "    \n",
    "    # Ensure all count features are integer-typed and handle missing values\n",
    "    # - Missing activity = 0 (user was inactive or never triggered the event)\n",
    "    # - Integer type is required for interpretability and modeling stability\n",
    "    users_merged[col] = (\n",
    "        users_merged[col]\n",
    "        .fillna(0)          # Replace NaN (no activity) with zero\n",
    "        .astype(int)         # Convert to integer (e.g., 3.0 → 3)\n",
    "    )\n",
    "\n",
    "# Post-processing verification \n",
    "print(\"Count features after standardization:\")\n",
    "print(users_merged[count_features].dtypes)\n",
    "print(users_merged[count_features].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e17431-4834-4b1a-b29d-27936326c590",
   "metadata": {},
   "source": [
    "## 5. Construct Time-Based Behavioral Features  \n",
    "These features are crucial churn predictors:\n",
    "\n",
    "- **Time to First Event:** Measures onboarding friction  \n",
    "- **Days Since Last Event:** Recency → strongest churn signal  \n",
    "\n",
    "We also introduce a sentinel value `999` to indicate *no activity recorded*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e463a7-20a8-4815-8d63-0bff36331eaf",
   "metadata": {},
   "source": [
    "### 4. Quick validation of engineered features\n",
    "\n",
    "Run simple diagnostics and plots to confirm the behavioral features now have variance (not all zeros).  \n",
    "We check:\n",
    "- unique counts per feature (should be >1 for most features)\n",
    "- min/max values\n",
    "- small histograms for sanity of distributions\n",
    "\n",
    "If these checks pass, proceed to modeling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "521f9bc3-233e-45ae-85f2-0daf4f7068ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timing features computed:\n",
      "       time_to_first_event_days  days_since_last_event\n",
      "count                    7043.0                 7043.0\n",
      "mean                      999.0                  999.0\n",
      "std                         0.0                    0.0\n",
      "min                       999.0                  999.0\n",
      "25%                       999.0                  999.0\n",
      "50%                       999.0                  999.0\n",
      "75%                       999.0                  999.0\n",
      "max                       999.0                  999.0\n",
      "\n",
      "Users with no first event: 7,043\n",
      "Users with no recent activity: 7,043\n"
     ]
    }
   ],
   "source": [
    "# Set analysis reference date (last observed date)\n",
    "reference_date = pd.to_datetime(\"2023-12-31\")\n",
    "\n",
    "# Reconstruct first/last event timestamps from aggregated columns if available\n",
    "for ts in ['first_event_ts', 'last_event_ts']:\n",
    "    ts_agg = ts + \"_agg\"\n",
    "    if ts_agg in users_merged.columns:\n",
    "        # Use pre-aggregated timestamp if exists; coerce errors to NaT\n",
    "        users_merged[ts] = pd.to_datetime(users_merged[ts_agg], errors='coerce')\n",
    "    else:\n",
    "        # No event data → mark as missing\n",
    "        users_merged[ts] = pd.NaT\n",
    "\n",
    "# Compute key behavioral timing features (in days)\n",
    "users_merged['time_to_first_event_days'] = (\n",
    "    (users_merged['first_event_ts'] - users_merged['start_date']).dt.days\n",
    "    .fillna(999)  # 999 = never had first event (high penalty value)\n",
    ")\n",
    "\n",
    "users_merged['days_since_last_event'] = (\n",
    "    (reference_date - users_merged['last_event_ts']).dt.days\n",
    "    .fillna(999)  # 999 = never active or no last event\n",
    ")\n",
    "\n",
    "# Confirmation: display summary of timing features\n",
    "print(\"Timing features computed:\")\n",
    "print(users_merged[['time_to_first_event_days', 'days_since_last_event']].describe().round(1))\n",
    "print(f\"\\nUsers with no first event: {(users_merged['time_to_first_event_days'] == 999).sum():,}\")\n",
    "print(f\"Users with no recent activity: {(users_merged['days_since_last_event'] == 999).sum():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc6fb56-6122-4d3b-944b-02836e18a5bb",
   "metadata": {},
   "source": [
    "## 6. Final Cleanup & Verification  \n",
    "We drop helper columns ending in `_agg` and inspect a random sample to verify:\n",
    "\n",
    "- Non-zero behavioral features  \n",
    "- Correct time delta calculations  \n",
    "- Aligned and clean user IDs  \n",
    "- No duplicate columns  \n",
    "\n",
    "This dataset is now fully ready for modeling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "68aea9eb-283a-4912-a486-9c7da7228e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final modeling dataset shape: (7043, 37)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerID</th>\n",
       "      <th>gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>OnlineBackup</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>StreamingTV</th>\n",
       "      <th>StreamingMovies</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "      <th>user_id</th>\n",
       "      <th>start_date</th>\n",
       "      <th>churned</th>\n",
       "      <th>churn_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>tenure_days</th>\n",
       "      <th>tenure_months_precise</th>\n",
       "      <th>events_count</th>\n",
       "      <th>unique_active_days</th>\n",
       "      <th>first_event_ts</th>\n",
       "      <th>last_event_ts</th>\n",
       "      <th>support_contacts_count</th>\n",
       "      <th>error_event_count</th>\n",
       "      <th>events_last_30d</th>\n",
       "      <th>time_to_first_event_days</th>\n",
       "      <th>days_since_last_event</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>1024-GUALD</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>24.80</td>\n",
       "      <td>24.80</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1024-GUALD</td>\n",
       "      <td>2023-11-30</td>\n",
       "      <td>True</td>\n",
       "      <td>2023-12-30</td>\n",
       "      <td>2023-12-30</td>\n",
       "      <td>30</td>\n",
       "      <td>0.99</td>\n",
       "      <td>136</td>\n",
       "      <td>118</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>37</td>\n",
       "      <td>999.0</td>\n",
       "      <td>999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2715</th>\n",
       "      <td>0484-JPBRU</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>41</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Bank transfer (automatic)</td>\n",
       "      <td>25.25</td>\n",
       "      <td>996.45</td>\n",
       "      <td>No</td>\n",
       "      <td>0484-JPBRU</td>\n",
       "      <td>2020-07-31</td>\n",
       "      <td>False</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>1248</td>\n",
       "      <td>41.00</td>\n",
       "      <td>67</td>\n",
       "      <td>65</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>999.0</td>\n",
       "      <td>999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3825</th>\n",
       "      <td>3620-EHIMZ</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>52</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>Two year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>19.35</td>\n",
       "      <td>1031.70</td>\n",
       "      <td>No</td>\n",
       "      <td>3620-EHIMZ</td>\n",
       "      <td>2019-08-31</td>\n",
       "      <td>False</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>1583</td>\n",
       "      <td>52.00</td>\n",
       "      <td>36</td>\n",
       "      <td>35</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>999.0</td>\n",
       "      <td>999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1807</th>\n",
       "      <td>6910-HADCM</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>No</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>76.35</td>\n",
       "      <td>76.35</td>\n",
       "      <td>Yes</td>\n",
       "      <td>6910-HADCM</td>\n",
       "      <td>2023-11-30</td>\n",
       "      <td>True</td>\n",
       "      <td>2023-12-30</td>\n",
       "      <td>2023-12-30</td>\n",
       "      <td>30</td>\n",
       "      <td>0.99</td>\n",
       "      <td>63</td>\n",
       "      <td>57</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>999.0</td>\n",
       "      <td>999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>8587-XYZSF</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>67</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Two year</td>\n",
       "      <td>No</td>\n",
       "      <td>Bank transfer (automatic)</td>\n",
       "      <td>50.55</td>\n",
       "      <td>3260.10</td>\n",
       "      <td>No</td>\n",
       "      <td>8587-XYZSF</td>\n",
       "      <td>2018-05-31</td>\n",
       "      <td>False</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>2040</td>\n",
       "      <td>67.02</td>\n",
       "      <td>155</td>\n",
       "      <td>137</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>49</td>\n",
       "      <td>999.0</td>\n",
       "      <td>999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263</th>\n",
       "      <td>6818-WOBHJ</td>\n",
       "      <td>Female</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>68</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Bank transfer (automatic)</td>\n",
       "      <td>89.60</td>\n",
       "      <td>6127.60</td>\n",
       "      <td>Yes</td>\n",
       "      <td>6818-WOBHJ</td>\n",
       "      <td>2018-04-30</td>\n",
       "      <td>True</td>\n",
       "      <td>2023-12-30</td>\n",
       "      <td>2023-12-30</td>\n",
       "      <td>2070</td>\n",
       "      <td>68.00</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>999.0</td>\n",
       "      <td>999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3732</th>\n",
       "      <td>3082-YVEKW</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>23</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Two year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Bank transfer (automatic)</td>\n",
       "      <td>77.15</td>\n",
       "      <td>1759.40</td>\n",
       "      <td>No</td>\n",
       "      <td>3082-YVEKW</td>\n",
       "      <td>2022-01-31</td>\n",
       "      <td>False</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>699</td>\n",
       "      <td>22.96</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>999.0</td>\n",
       "      <td>999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1672</th>\n",
       "      <td>4737-AQCPU</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>72</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Two year</td>\n",
       "      <td>No</td>\n",
       "      <td>Credit card (automatic)</td>\n",
       "      <td>72.10</td>\n",
       "      <td>5016.65</td>\n",
       "      <td>No</td>\n",
       "      <td>4737-AQCPU</td>\n",
       "      <td>2017-12-31</td>\n",
       "      <td>False</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>2191</td>\n",
       "      <td>71.98</td>\n",
       "      <td>53</td>\n",
       "      <td>51</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>999.0</td>\n",
       "      <td>999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>4853-RULSV</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>70</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Two year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Credit card (automatic)</td>\n",
       "      <td>104.00</td>\n",
       "      <td>7250.15</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4853-RULSV</td>\n",
       "      <td>2018-02-28</td>\n",
       "      <td>True</td>\n",
       "      <td>2023-12-28</td>\n",
       "      <td>2023-12-28</td>\n",
       "      <td>2129</td>\n",
       "      <td>69.94</td>\n",
       "      <td>50</td>\n",
       "      <td>49</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>999.0</td>\n",
       "      <td>999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2526</th>\n",
       "      <td>5766-ZJYBB</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>19.40</td>\n",
       "      <td>19.40</td>\n",
       "      <td>Yes</td>\n",
       "      <td>5766-ZJYBB</td>\n",
       "      <td>2023-11-30</td>\n",
       "      <td>True</td>\n",
       "      <td>2023-12-30</td>\n",
       "      <td>2023-12-30</td>\n",
       "      <td>30</td>\n",
       "      <td>0.99</td>\n",
       "      <td>72</td>\n",
       "      <td>65</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>999.0</td>\n",
       "      <td>999.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      customerID  gender  SeniorCitizen Partner Dependents  tenure PhoneService     MultipleLines InternetService       OnlineSecurity  \\\n",
       "185   1024-GUALD  Female              0     Yes         No       1           No  No phone service             DSL                   No   \n",
       "2715  0484-JPBRU    Male              0      No         No      41          Yes               Yes              No  No internet service   \n",
       "3825  3620-EHIMZ  Female              0     Yes        Yes      52          Yes                No              No  No internet service   \n",
       "1807  6910-HADCM  Female              0      No         No       1          Yes                No     Fiber optic                   No   \n",
       "132   8587-XYZSF    Male              0      No         No      67          Yes                No             DSL                   No   \n",
       "1263  6818-WOBHJ  Female              1     Yes         No      68          Yes               Yes     Fiber optic                   No   \n",
       "3732  3082-YVEKW  Female              0     Yes        Yes      23          Yes               Yes             DSL                  Yes   \n",
       "1672  4737-AQCPU    Male              0     Yes        Yes      72          Yes               Yes             DSL                  Yes   \n",
       "811   4853-RULSV    Male              0      No         No      70          Yes               Yes     Fiber optic                  Yes   \n",
       "2526  5766-ZJYBB    Male              0      No         No       1          Yes                No              No  No internet service   \n",
       "\n",
       "             OnlineBackup     DeviceProtection          TechSupport          StreamingTV      StreamingMovies        Contract  \\\n",
       "185                    No                   No                   No                   No                   No  Month-to-month   \n",
       "2715  No internet service  No internet service  No internet service  No internet service  No internet service  Month-to-month   \n",
       "3825  No internet service  No internet service  No internet service  No internet service  No internet service        Two year   \n",
       "1807                   No                  Yes                   No                   No                   No  Month-to-month   \n",
       "132                    No                   No                  Yes                   No                   No        Two year   \n",
       "1263                  Yes                   No                   No                   No                  Yes  Month-to-month   \n",
       "3732                   No                  Yes                  Yes                  Yes                   No        Two year   \n",
       "1672                  Yes                  Yes                  Yes                   No                   No        Two year   \n",
       "811                    No                   No                  Yes                  Yes                  Yes        Two year   \n",
       "2526  No internet service  No internet service  No internet service  No internet service  No internet service  Month-to-month   \n",
       "\n",
       "     PaperlessBilling              PaymentMethod  MonthlyCharges  TotalCharges Churn     user_id start_date  churned churn_date  \\\n",
       "185               Yes           Electronic check           24.80         24.80   Yes  1024-GUALD 2023-11-30     True 2023-12-30   \n",
       "2715              Yes  Bank transfer (automatic)           25.25        996.45    No  0484-JPBRU 2020-07-31    False        NaT   \n",
       "3825               No               Mailed check           19.35       1031.70    No  3620-EHIMZ 2019-08-31    False        NaT   \n",
       "1807               No           Electronic check           76.35         76.35   Yes  6910-HADCM 2023-11-30     True 2023-12-30   \n",
       "132                No  Bank transfer (automatic)           50.55       3260.10    No  8587-XYZSF 2018-05-31    False        NaT   \n",
       "1263              Yes  Bank transfer (automatic)           89.60       6127.60   Yes  6818-WOBHJ 2018-04-30     True 2023-12-30   \n",
       "3732              Yes  Bank transfer (automatic)           77.15       1759.40    No  3082-YVEKW 2022-01-31    False        NaT   \n",
       "1672               No    Credit card (automatic)           72.10       5016.65    No  4737-AQCPU 2017-12-31    False        NaT   \n",
       "811               Yes    Credit card (automatic)          104.00       7250.15   Yes  4853-RULSV 2018-02-28     True 2023-12-28   \n",
       "2526               No               Mailed check           19.40         19.40   Yes  5766-ZJYBB 2023-11-30     True 2023-12-30   \n",
       "\n",
       "        end_date  tenure_days  tenure_months_precise  events_count  unique_active_days first_event_ts last_event_ts  \\\n",
       "185   2023-12-30           30                   0.99           136                 118            NaT           NaT   \n",
       "2715  2023-12-31         1248                  41.00            67                  65            NaT           NaT   \n",
       "3825  2023-12-31         1583                  52.00            36                  35            NaT           NaT   \n",
       "1807  2023-12-30           30                   0.99            63                  57            NaT           NaT   \n",
       "132   2023-12-31         2040                  67.02           155                 137            NaT           NaT   \n",
       "1263  2023-12-30         2070                  68.00            52                  52            NaT           NaT   \n",
       "3732  2023-12-31          699                  22.96            31                  29            NaT           NaT   \n",
       "1672  2023-12-31         2191                  71.98            53                  51            NaT           NaT   \n",
       "811   2023-12-28         2129                  69.94            50                  49            NaT           NaT   \n",
       "2526  2023-12-30           30                   0.99            72                  65            NaT           NaT   \n",
       "\n",
       "      support_contacts_count  error_event_count  events_last_30d  time_to_first_event_days  days_since_last_event  \n",
       "185                        0                  8               37                     999.0                  999.0  \n",
       "2715                       2                  0               22                     999.0                  999.0  \n",
       "3825                       1                  0               11                     999.0                  999.0  \n",
       "1807                       1                  2               16                     999.0                  999.0  \n",
       "132                        4                  4               49                     999.0                  999.0  \n",
       "1263                       1                  2               19                     999.0                  999.0  \n",
       "3732                       0                  1                5                     999.0                  999.0  \n",
       "1672                       0                  2               13                     999.0                  999.0  \n",
       "811                        1                  2               14                     999.0                  999.0  \n",
       "2526                       2                  1               26                     999.0                  999.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved processed dataset with 7043 rows to ../data/processed/users_final.csv\n"
     ]
    }
   ],
   "source": [
    "# Drop helper columns\n",
    "agg_cols = [c for c in users_merged.columns if c.endswith('_agg')]\n",
    "users_final = users_merged.drop(columns=agg_cols)\n",
    "\n",
    "print(\"Final modeling dataset shape:\", users_final.shape)\n",
    "\n",
    "# Preview a few rows\n",
    "display(users_final.sample(10, random_state=42))\n",
    "\n",
    "# Replace canonical users dataset\n",
    "users = users_final.copy()\n",
    "\n",
    "# Save the final processed dataset for use in modeling notebook\n",
    "users.to_csv('../data/processed/users_final.csv', index=False)\n",
    "print(f\"Saved processed dataset with {len(users)} rows to ../data/processed/users_final.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
